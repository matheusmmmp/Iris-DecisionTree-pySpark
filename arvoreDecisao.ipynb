{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "**Notebook utilizado para um estudo sobre árvore de decisão e floresta randômica**"
      ],
      "metadata": {
        "id": "TYlCl3eCnMqB"
      }
    },
    {
      "metadata": {
        "id": "sq8U3BtmhtRx"
      },
      "cell_type": "markdown",
      "source": [
        "\n",
        "# **Executando o Pyspark no Colab**\n",
        "\n",
        "Para executar o spark no Colab, precisamos primeiro instalar todas as dependências no ambiente Colab, ou seja, Apache Spark 2.3.2 com hadoop 2.7, Java 8 e Findspark para localizar o spark no sistema. Siga as etapas para instalar as dependências:"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!sudo apt update\n",
        "!sudo apt-get install openjdk-8-jdk-headless -qq > /dev/null\n",
        "!wget -q https://archive.apache.org/dist/spark/spark-2.4.4/spark-2.4.4-bin-hadoop2.7.tgz\n",
        "!tar xf spark-2.4.4-bin-hadoop2.7.tgz\n",
        "!pip install -q findspark\n",
        "import os\n",
        "os.environ[\"JAVA_HOME\"] = \"/usr/lib/jvm/java-8-openjdk-amd64\"\n",
        "os.environ[\"SPARK_HOME\"] = \"/content/spark-2.4.4-bin-hadoop2.7\"\n",
        "import findspark\n",
        "findspark.init('spark-2.4.4-bin-hadoop2.7')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vUZPw4ogbsZh",
        "outputId": "608cb591-e086-4dd6-d94b-caf7c53ca0cb"
      },
      "execution_count": 65,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[33m\r0% [Working]\u001b[0m\r            \rHit:1 https://cloud.r-project.org/bin/linux/ubuntu bionic-cran40/ InRelease\n",
            "\u001b[33m\r0% [Connecting to archive.ubuntu.com (91.189.88.152)] [Connecting to security.u\u001b[0m\u001b[33m\r0% [1 InRelease gpgv 3,626 B] [Connecting to archive.ubuntu.com (91.189.88.152)\u001b[0m\r                                                                               \rIgn:2 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu1804/x86_64  InRelease\n",
            "\u001b[33m\r0% [1 InRelease gpgv 3,626 B] [Connecting to archive.ubuntu.com (91.189.88.152)\u001b[0m\r                                                                               \rIgn:3 https://developer.download.nvidia.com/compute/machine-learning/repos/ubuntu1804/x86_64  InRelease\n",
            "\u001b[33m\r0% [1 InRelease gpgv 3,626 B] [Connecting to archive.ubuntu.com (91.189.88.152)\u001b[0m\r                                                                               \rHit:4 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu1804/x86_64  Release\n",
            "\u001b[33m\r0% [1 InRelease gpgv 3,626 B] [Connecting to archive.ubuntu.com (91.189.88.152)\u001b[0m\r                                                                               \rHit:5 https://developer.download.nvidia.com/compute/machine-learning/repos/ubuntu1804/x86_64  Release\n",
            "Hit:6 http://security.ubuntu.com/ubuntu bionic-security InRelease\n",
            "Hit:8 http://archive.ubuntu.com/ubuntu bionic InRelease\n",
            "Hit:9 http://ppa.launchpad.net/c2d4u.team/c2d4u4.0+/ubuntu bionic InRelease\n",
            "Hit:11 http://archive.ubuntu.com/ubuntu bionic-updates InRelease\n",
            "Hit:12 http://archive.ubuntu.com/ubuntu bionic-backports InRelease\n",
            "Hit:13 http://ppa.launchpad.net/cran/libgit2/ubuntu bionic InRelease\n",
            "Hit:14 http://ppa.launchpad.net/deadsnakes/ppa/ubuntu bionic InRelease\n",
            "Hit:15 http://ppa.launchpad.net/graphics-drivers/ppa/ubuntu bionic InRelease\n",
            "Reading package lists... Done\n",
            "Building dependency tree       \n",
            "Reading state information... Done\n",
            "85 packages can be upgraded. Run 'apt list --upgradable' to see them.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.sql import SparkSession #importa a biblioteca que cria a seção do spark\n",
        "spark = SparkSession.builder \\\n",
        "    .master(\"local[*]\") \\\n",
        "    .appName(\"ArvoreDecisao\") \\\n",
        "    .getOrCreate()\n",
        "import pyspark.sql.functions as f\n",
        "import pyspark.sql.types as t\n",
        "from pyspark.sql.types import *\n",
        "from pyspark.sql.functions import *"
      ],
      "metadata": {
        "id": "9RzK0ONmZa6X"
      },
      "outputs": [],
      "execution_count": 66
    },
    {
      "metadata": {
        "id": "JEb4HTRwiaJx"
      },
      "cell_type": "markdown",
      "source": [
        "Agora com o Colab pronto para executar o Spark, será construido um modelo de Árvore de Decisão.\n",
        "\n",
        "# **Árvore de Decisão**\n",
        "\n",
        "A árvore de decisão é um dos métodos mais comuns no aprendizado de máquina mais antigas e amplamente utilizadas, que pressupõe uma relação entre variáveis. Esses algoritmos subdividem progressivamente os dados em conjuntos cada vez menores e mais específicos, em termos de seus atributos, até atingirem um tamanho simplificado o bastante para ser rotulado. Para isso é necessário treinar o modelo com dados previamente rotulados, de modo a aplicá-lo a dados novos.\n",
        "\n",
        "O objetivo deste exercício é prever a espécie de íris de uma flor pelas características dadas. Vamos prever a espécie através do conjunto de dados de  3 espécies de íris onde foram coletadas 50 amostras para cada uma espécie, considerando a espécie como a variável de saída e as outras variáveis de tamanhos de pétalas e sépalas como entrada.\n",
        "\n",
        "Baixe o conjunto de dados [aqui](https://www.kaggle.com/uciml/iris) e mantenha-o em algum lugar no seu computador. Carregue o conjunto de dados em seu diretório Colab a partir de seu sistema local:"
      ]
    },
    {
      "metadata": {
        "id": "KwrqMk3HiMiE"
      },
      "cell_type": "markdown",
      "source": [
        "## **Conhecendo o Bando de Dados**"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Diretório que contém o arquivo a ser utilizado\n",
        "diretorioArvore=\"iris_bezdekIris.csv\"  "
      ],
      "metadata": {
        "id": "1TbGzw5vZa6Y"
      },
      "outputs": [],
      "execution_count": 67
    },
    {
      "metadata": {
        "id": "21D9EANUvnwF"
      },
      "cell_type": "markdown",
      "source": [
        "Inicialmente é necessário carregar o conjunto de dados, após isso, é possivel definir um esquema para uma analise prévia dos mesmos"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Lendo arquivos armazenados CSV com o esquema definido\n",
        "df_iris = spark.read.format('csv').options(inferSchema=True,header='false',delimiter=',').load(diretorioArvore)"
      ],
      "metadata": {
        "id": "tolfUQ0BZa6Z"
      },
      "outputs": [],
      "execution_count": 68
    },
    {
      "metadata": {
        "id": "UJLoAfqVv8-E"
      },
      "cell_type": "markdown",
      "source": [
        "Observe que usamos InferSchema dentro do read.csv. InferSchema nos permite inferir automaticamente diferentes tipos de dados para cada coluna.\n",
        "\n",
        "Vamos imprimir uma olhada no conjunto de dados para ver os tipos de dados de cada coluna:"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df_iris.printSchema()"
      ],
      "metadata": {
        "id": "XV3XX94fZa6a",
        "outputId": "9f8373ea-db16-4423-9d98-ab4bf2d50211",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "root\n",
            " |-- _c0: double (nullable = true)\n",
            " |-- _c1: double (nullable = true)\n",
            " |-- _c2: double (nullable = true)\n",
            " |-- _c3: double (nullable = true)\n",
            " |-- _c4: string (nullable = true)\n",
            "\n"
          ]
        }
      ],
      "execution_count": 69
    },
    {
      "cell_type": "code",
      "source": [
        "df_iris.show(5)"
      ],
      "metadata": {
        "id": "fxVfDRbqZa6a",
        "outputId": "5d225b50-6dc9-4308-eb99-a7697c22f66d",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+---+---+---+---+-----------+\n",
            "|_c0|_c1|_c2|_c3|        _c4|\n",
            "+---+---+---+---+-----------+\n",
            "|5.1|3.5|1.4|0.2|Iris-setosa|\n",
            "|4.9|3.0|1.4|0.2|Iris-setosa|\n",
            "|4.7|3.2|1.3|0.2|Iris-setosa|\n",
            "|4.6|3.1|1.5|0.2|Iris-setosa|\n",
            "|5.0|3.6|1.4|0.2|Iris-setosa|\n",
            "+---+---+---+---+-----------+\n",
            "only showing top 5 rows\n",
            "\n"
          ]
        }
      ],
      "execution_count": 70
    },
    {
      "cell_type": "markdown",
      "source": [
        "A fim de gerar melhor entendimento, os nomes das colunas no cabeçalho vão ser alterados, permitindo assim identificar com maior clareza a qual dado aquela informação corresponde."
      ],
      "metadata": {
        "id": "_1gRmeaKtpmw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Modificando o nome das colunas existentes no cabeçalho \n",
        "df_iris = df_iris.selectExpr(\"_c0 as sep_len\", \"_c1 as sep_wid\", \"_c2 as pet_len\", \"_c3 as pet_wid\", \"_c4 as label\")"
      ],
      "metadata": {
        "id": "mkCUhiPAZa6b"
      },
      "outputs": [],
      "execution_count": 71
    },
    {
      "cell_type": "code",
      "source": [
        "df_iris.show(5)"
      ],
      "metadata": {
        "id": "lC-70GvMZa6c",
        "outputId": "21e65fcc-67f7-4620-f109-48b7720eea1c",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-------+-------+-------+-------+-----------+\n",
            "|sep_len|sep_wid|pet_len|pet_wid|      label|\n",
            "+-------+-------+-------+-------+-----------+\n",
            "|    5.1|    3.5|    1.4|    0.2|Iris-setosa|\n",
            "|    4.9|    3.0|    1.4|    0.2|Iris-setosa|\n",
            "|    4.7|    3.2|    1.3|    0.2|Iris-setosa|\n",
            "|    4.6|    3.1|    1.5|    0.2|Iris-setosa|\n",
            "|    5.0|    3.6|    1.4|    0.2|Iris-setosa|\n",
            "+-------+-------+-------+-------+-----------+\n",
            "only showing top 5 rows\n",
            "\n"
          ]
        }
      ],
      "execution_count": 72
    },
    {
      "cell_type": "markdown",
      "source": [
        "Por fim, uma analise prévia das informações apresentadas no conjunto de dados"
      ],
      "metadata": {
        "id": "cOTMUaEcuUY5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Encontrando as \"estatísticas\"\n",
        "df_iris.describe(['sep_len','sep_wid','pet_len','pet_wid']).show()"
      ],
      "metadata": {
        "id": "ltOZJGebZa6d",
        "outputId": "e5a244bb-c56e-4572-a93a-56f7748c02ac",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-------+------------------+-------------------+------------------+------------------+\n",
            "|summary|           sep_len|            sep_wid|           pet_len|           pet_wid|\n",
            "+-------+------------------+-------------------+------------------+------------------+\n",
            "|  count|               150|                150|               150|               150|\n",
            "|   mean| 5.843333333333335|  3.057333333333334|3.7580000000000027| 1.199333333333334|\n",
            "| stddev|0.8280661279778637|0.43586628493669793|1.7652982332594662|0.7622376689603467|\n",
            "|    min|               4.3|                2.0|               1.0|               0.1|\n",
            "|    max|               7.9|                4.4|               6.9|               2.5|\n",
            "+-------+------------------+-------------------+------------------+------------------+\n",
            "\n"
          ]
        }
      ],
      "execution_count": 73
    },
    {
      "cell_type": "code",
      "source": [
        "#Definindo a visão do dataframe para ser utilizado como uma tabela pelo SQL\n",
        "df_iris.createOrReplaceTempView(\"irisTable\")\n",
        "display(spark.sql('select * from irisTable'))"
      ],
      "metadata": {
        "id": "FPD9xOyJZa6e",
        "outputId": "338dec07-eba6-453c-a762-c568d2947a50",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        }
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "DataFrame[sep_len: double, sep_wid: double, pet_len: double, pet_wid: double, label: string]"
            ]
          },
          "metadata": {}
        }
      ],
      "execution_count": 74
    },
    {
      "metadata": {
        "id": "R6g2D6LucoDA"
      },
      "cell_type": "markdown",
      "source": [
        "\n",
        "## **Iniciando o Processo de Construção e Aplicação da Árvore de Decisão**\n",
        "\n",
        "Agora que carregamos o conjunto de dados, podemos começar a analisar.\n",
        "Para a árvore de decisão, precisamos importar dois módulos do Pyspark, ou seja, Vector Assembler e StringIndexer. O Vector Assembler é um transformador que reúne todos os recursos em um vetor a partir de várias colunas que contêm o tipo duplo. O StringIndexer é utilizado para as colunas quem contém valores de string para convertê-la em valores numéricos."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.ml.linalg import Vectors  #Biblioteca que contém funções de Algebra Linear\n",
        "from pyspark.ml.feature import VectorAssembler #Biblioteca que contém as funções para a construção de vetores\n",
        "from pyspark.ml.feature import StringIndexer  #Cria o 'vetor' para cada uma das classes existentes na coluna label"
      ],
      "metadata": {
        "id": "40x-1jxrZa6f"
      },
      "outputs": [],
      "execution_count": 75
    },
    {
      "metadata": {
        "id": "cGGmsdoWhYE0"
      },
      "cell_type": "markdown",
      "source": [
        "O próximo passo é converter todos os recursos de diferentes colunas em uma única coluna e vamos chamar esta nova coluna de vetor como 'features' no outputCol"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Criando o vetor de características\n",
        "vector_assembler = VectorAssembler(inputCols=[\"sep_len\", \"sep_wid\", \"pet_len\", \"pet_wid\"],outputCol=\"features\")\n",
        "df_temp = vector_assembler.transform(df_iris)\n",
        "df_temp.show(5)"
      ],
      "metadata": {
        "id": "eiMQmWldZa6f",
        "outputId": "bd8a27b9-abc4-43b3-93a5-28658c4dbdc1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-------+-------+-------+-------+-----------+-----------------+\n",
            "|sep_len|sep_wid|pet_len|pet_wid|      label|         features|\n",
            "+-------+-------+-------+-------+-----------+-----------------+\n",
            "|    5.1|    3.5|    1.4|    0.2|Iris-setosa|[5.1,3.5,1.4,0.2]|\n",
            "|    4.9|    3.0|    1.4|    0.2|Iris-setosa|[4.9,3.0,1.4,0.2]|\n",
            "|    4.7|    3.2|    1.3|    0.2|Iris-setosa|[4.7,3.2,1.3,0.2]|\n",
            "|    4.6|    3.1|    1.5|    0.2|Iris-setosa|[4.6,3.1,1.5,0.2]|\n",
            "|    5.0|    3.6|    1.4|    0.2|Iris-setosa|[5.0,3.6,1.4,0.2]|\n",
            "+-------+-------+-------+-------+-----------+-----------------+\n",
            "only showing top 5 rows\n",
            "\n"
          ]
        }
      ],
      "execution_count": 76
    },
    {
      "cell_type": "code",
      "source": [
        "#Removendo as colunas que não serão utilizadas\n",
        "df_menor = df_temp.drop('sep_len', 'sep_wid', 'pet_len', 'pet_wid')\n",
        "df_menor.show(5)"
      ],
      "metadata": {
        "id": "3LE-l4DRZa6g",
        "outputId": "da589eb3-38d2-49f9-f14c-31e6edf260c5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-----------+-----------------+\n",
            "|      label|         features|\n",
            "+-----------+-----------------+\n",
            "|Iris-setosa|[5.1,3.5,1.4,0.2]|\n",
            "|Iris-setosa|[4.9,3.0,1.4,0.2]|\n",
            "|Iris-setosa|[4.7,3.2,1.3,0.2]|\n",
            "|Iris-setosa|[4.6,3.1,1.5,0.2]|\n",
            "|Iris-setosa|[5.0,3.6,1.4,0.2]|\n",
            "+-----------+-----------------+\n",
            "only showing top 5 rows\n",
            "\n"
          ]
        }
      ],
      "execution_count": 77
    },
    {
      "metadata": {
        "id": "dNgFCto2wHLd"
      },
      "cell_type": "markdown",
      "source": [
        "A coluna 'features' refere-se aos recursos de entrada de todas as colunas e 'label' é a coluna de destino."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Aplicando as transformações para a coluna label\n",
        "l_indexer = StringIndexer(inputCol=\"label\", outputCol=\"labelIndex\")  #Cria o objeto para a codificação\n",
        "df_final = l_indexer.fit(df_menor).transform(df_menor)  #Aplica a transformação"
      ],
      "metadata": {
        "id": "IOCFEuIbZa6g"
      },
      "outputs": [],
      "execution_count": 78
    },
    {
      "cell_type": "code",
      "source": [
        "df_final.show(5)"
      ],
      "metadata": {
        "id": "_es1tJfbZa6g",
        "outputId": "bae99663-ef44-4c80-e4f9-3a3b3d8b9ab2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-----------+-----------------+----------+\n",
            "|      label|         features|labelIndex|\n",
            "+-----------+-----------------+----------+\n",
            "|Iris-setosa|[5.1,3.5,1.4,0.2]|       0.0|\n",
            "|Iris-setosa|[4.9,3.0,1.4,0.2]|       0.0|\n",
            "|Iris-setosa|[4.7,3.2,1.3,0.2]|       0.0|\n",
            "|Iris-setosa|[4.6,3.1,1.5,0.2]|       0.0|\n",
            "|Iris-setosa|[5.0,3.6,1.4,0.2]|       0.0|\n",
            "+-----------+-----------------+----------+\n",
            "only showing top 5 rows\n",
            "\n"
          ]
        }
      ],
      "execution_count": 79
    },
    {
      "cell_type": "markdown",
      "source": [
        "Em seguida, devemos dividir os dados de treinamento e teste de acordo com nosso conjunto de dados (0,7 e 0,3 neste caso)."
      ],
      "metadata": {
        "id": "vNXFKRO6wiaK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Dividindo entre dados de treinamento e teste\n",
        "(train, test) = df_final.randomSplit([0.7, 0.3])"
      ],
      "metadata": {
        "id": "xC6qG_4LZa6h"
      },
      "outputs": [],
      "execution_count": 80
    },
    {
      "cell_type": "code",
      "source": [
        "test.show(5)"
      ],
      "metadata": {
        "id": "syiNpom9Za6h",
        "outputId": "ed0cc95e-9003-4e78-85b0-aeb30a4de2e8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-----------+-----------------+----------+\n",
            "|      label|         features|labelIndex|\n",
            "+-----------+-----------------+----------+\n",
            "|Iris-setosa|[4.4,2.9,1.4,0.2]|       0.0|\n",
            "|Iris-setosa|[4.4,3.0,1.3,0.2]|       0.0|\n",
            "|Iris-setosa|[4.4,3.2,1.3,0.2]|       0.0|\n",
            "|Iris-setosa|[4.6,3.1,1.5,0.2]|       0.0|\n",
            "|Iris-setosa|[4.6,3.4,1.4,0.3]|       0.0|\n",
            "+-----------+-----------------+----------+\n",
            "only showing top 5 rows\n",
            "\n"
          ]
        }
      ],
      "execution_count": 81
    },
    {
      "cell_type": "markdown",
      "source": [
        "## ***Definindo o Algoritmo***"
      ],
      "metadata": {
        "id": "63k09N1KZa6h"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Para o algoritmo de Árvore de Decisão, será utilizado o modulo do Pyspark DecisionTreeClassifier, onde é definido um modelo e aplicado um treinamento no mesmo.\n",
        "E podemos ir um pouco além e analisar nosso modelo estatisticamente importando o modulo do Pyspark MulticlassClassificationEvaluator, permitindo avaliar a precisão do modelo de árvore de decisão."
      ],
      "metadata": {
        "id": "F4MYQlJGx_Cn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.ml.classification import DecisionTreeClassifier  #Biblioteca para o algoritmo da árvore de decisão\n",
        "from pyspark.ml.evaluation import MulticlassClassificationEvaluator  #Utilizada para encontrar as métricas de desempenho"
      ],
      "metadata": {
        "id": "7zsTtK6tZa6h"
      },
      "outputs": [],
      "execution_count": 82
    },
    {
      "cell_type": "code",
      "source": [
        "modeloArvore = DecisionTreeClassifier(labelCol=\"labelIndex\", featuresCol=\"features\")  #Definindo o modelo\n",
        "model = modeloArvore.fit(train)  #Aplicando o treinamento"
      ],
      "metadata": {
        "id": "ffDk1KnlZa6i"
      },
      "outputs": [],
      "execution_count": 83
    },
    {
      "cell_type": "code",
      "source": [
        "#Realizando a previsão\n",
        "predictions = model.transform(test)\n",
        "predictions.select(\"prediction\", \"labelIndex\").show(5)"
      ],
      "metadata": {
        "id": "fkJJ4y0AZa6i",
        "outputId": "1f2bd826-4444-4e11-a48a-380290c7383b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+----------+----------+\n",
            "|prediction|labelIndex|\n",
            "+----------+----------+\n",
            "|       0.0|       0.0|\n",
            "|       0.0|       0.0|\n",
            "|       0.0|       0.0|\n",
            "|       0.0|       0.0|\n",
            "|       0.0|       0.0|\n",
            "+----------+----------+\n",
            "only showing top 5 rows\n",
            "\n"
          ]
        }
      ],
      "execution_count": 84
    },
    {
      "cell_type": "markdown",
      "source": [
        "Após a previsão, é possivel avaliar a precisão do modelo através dos seguintes comandos:"
      ],
      "metadata": {
        "id": "rgGb9VhEyFt-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Encontrando as métricas de avaliação para o modelo\n",
        "avaliacao = MulticlassClassificationEvaluator(labelCol=\"labelIndex\", predictionCol=\"prediction\",metricName=\"accuracy\")"
      ],
      "metadata": {
        "id": "L3ngvMSLZa6i"
      },
      "outputs": [],
      "execution_count": 85
    },
    {
      "cell_type": "code",
      "source": [
        "acuracia = avaliacao.evaluate(predictions)\n",
        "print(\"Acurácia do Modelo =  \",(acuracia))"
      ],
      "metadata": {
        "id": "1hw-Y8vEZa6i",
        "outputId": "0e51ffc9-2ee2-4f6c-d1b7-f01f40649e39",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Acurácia do Modelo =   0.9056603773584906\n"
          ]
        }
      ],
      "execution_count": 86
    },
    {
      "metadata": {
        "id": "U35WL_khczBG"
      },
      "cell_type": "markdown",
      "source": [
        "\n",
        "# **Aplicação da Floresta Randômica**\n",
        "\n",
        "Para a aplicação da floresta randomica, precisamos importar um módulos do Pyspark, o RandomForestClassifier. Com o RandomForestClassifier é possivel definir e analisar um modelo de floresta randomica."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.ml.classification import RandomForestClassifier  #Classificador para o randomForest"
      ],
      "metadata": {
        "id": "yAds9T0cZa6j"
      },
      "outputs": [],
      "execution_count": 21
    },
    {
      "cell_type": "code",
      "source": [
        "modeloRF = RandomForestClassifier(labelCol=\"labelIndex\",featuresCol=\"features\", numTrees=10)  #Define o modelo\n",
        "modelRF = modeloRF.fit(train)"
      ],
      "metadata": {
        "id": "y5Dfsxx5Za6j"
      },
      "outputs": [],
      "execution_count": 22
    },
    {
      "cell_type": "code",
      "source": [
        "#Realizando a previsão\n",
        "predictions = modelRF.transform(test)\n",
        "predictions.select(\"prediction\", \"labelIndex\").show(5)"
      ],
      "metadata": {
        "id": "RHHkk7NHZa6j",
        "outputId": "14c7e69b-4572-42e0-f207-b540fd6ba68c",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+----------+----------+\n",
            "|prediction|labelIndex|\n",
            "+----------+----------+\n",
            "|       0.0|       0.0|\n",
            "|       0.0|       0.0|\n",
            "|       0.0|       0.0|\n",
            "|       0.0|       0.0|\n",
            "|       0.0|       0.0|\n",
            "+----------+----------+\n",
            "only showing top 5 rows\n",
            "\n"
          ]
        }
      ],
      "execution_count": 23
    },
    {
      "cell_type": "code",
      "source": [
        "#Encontrando as métricas de avaliação para o modelo\n",
        "avaliacao = MulticlassClassificationEvaluator(labelCol=\"labelIndex\", predictionCol=\"prediction\",metricName=\"accuracy\")"
      ],
      "metadata": {
        "id": "6wVrBlqGZa6j"
      },
      "outputs": [],
      "execution_count": 60
    },
    {
      "cell_type": "code",
      "source": [
        "acuracia = avaliacao.evaluate(predictions)\n",
        "print(\"Acurácia do Modelo =  \",(acuracia))"
      ],
      "metadata": {
        "id": "u_znpnRGZa6k",
        "outputId": "4440f3a6-57dc-4a9b-ff61-57bcb7956d7e",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Acurácia do Modelo =   0.9433962264150944\n"
          ]
        }
      ],
      "execution_count": 25
    },
    {
      "cell_type": "code",
      "source": [
        "print(modelRF)"
      ],
      "metadata": {
        "id": "Z7RezOh3Za6k",
        "outputId": "9ee25a9a-e576-40c6-bf46-37caebeb5c73",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "RandomForestClassificationModel (uid=RandomForestClassifier_d46e066f807c) with 10 trees\n"
          ]
        }
      ],
      "execution_count": 26
    }
  ],
  "metadata": {
    "name": "regressao",
    "notebookId": 2179804067390125,
    "colab": {
      "name": "arvoreDecisao.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "JEb4HTRwiaJx",
        "KwrqMk3HiMiE",
        "R6g2D6LucoDA"
      ],
      "toc_visible": true
    },
    "language_info": {
      "name": "python"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}